{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d22a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 10:56:22.603147: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow as tf \n",
    "import random\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec253f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/linhdangvu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: LMG128\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 8\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.170s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m1.24765\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 002 | loss: 1.24765 - acc: 0.3375 -- iter: 8/8\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m1.36061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 003 | loss: 1.36061 - acc: 0.4705 -- iter: 8/8\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m1.37902\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 004 | loss: 1.37902 - acc: 0.4926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m1.38287\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 005 | loss: 1.38287 - acc: 0.4977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m1.38359\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 006 | loss: 1.38359 - acc: 0.4992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m1.38348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 007 | loss: 1.38348 - acc: 0.4997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m1.38310\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 008 | loss: 1.38310 - acc: 0.4999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m1.38261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 009 | loss: 1.38261 - acc: 0.4999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m1.38208\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 010 | loss: 1.38208 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m1.38152\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 011 | loss: 1.38152 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m1.38095\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 012 | loss: 1.38095 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m1.38035\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 013 | loss: 1.38035 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m1.37975\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 014 | loss: 1.37975 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m1.37912\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 015 | loss: 1.37912 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m1.37848\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 016 | loss: 1.37848 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1.37783\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 017 | loss: 1.37783 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.37715\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 018 | loss: 1.37715 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m1.37646\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 019 | loss: 1.37646 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m1.37574\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 020 | loss: 1.37574 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m1.37501\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 021 | loss: 1.37501 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m1.37425\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 022 | loss: 1.37425 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m1.37347\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 023 | loss: 1.37347 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m1.37266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 024 | loss: 1.37266 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m1.37183\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 025 | loss: 1.37183 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m1.37098\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 026 | loss: 1.37098 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m1.37009\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 027 | loss: 1.37009 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m1.36918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 028 | loss: 1.36918 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m1.36823\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 029 | loss: 1.36823 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m1.36725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 030 | loss: 1.36725 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m1.36624\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 031 | loss: 1.36624 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m1.36519\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 032 | loss: 1.36519 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m1.36411\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 033 | loss: 1.36411 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m1.36298\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 034 | loss: 1.36298 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m1.36182\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 035 | loss: 1.36182 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m1.36061\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 036 | loss: 1.36061 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m1.35936\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 037 | loss: 1.35936 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m1.35806\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 038 | loss: 1.35806 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m1.35672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 039 | loss: 1.35672 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m1.35533\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 040 | loss: 1.35533 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m1.35388\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 041 | loss: 1.35388 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m1.35238\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 042 | loss: 1.35238 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m1.35083\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 043 | loss: 1.35083 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m1.34922\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 044 | loss: 1.34922 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m1.34755\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 045 | loss: 1.34755 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m1.34581\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 046 | loss: 1.34581 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m1.34402\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 047 | loss: 1.34402 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m1.34510\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 048 | loss: 1.34510 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m1.34273\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 049 | loss: 1.34273 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m1.34040\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 050 | loss: 1.34040 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m1.33807\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 051 | loss: 1.33807 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m1.33574\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 052 | loss: 1.33574 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m1.33339\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 053 | loss: 1.33339 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m1.33100\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 054 | loss: 1.33100 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m1.32856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 055 | loss: 1.32856 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m1.32607\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 056 | loss: 1.32607 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m1.32352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 057 | loss: 1.32352 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m1.32091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 058 | loss: 1.32091 - acc: 0.5000 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m1.31822\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 059 | loss: 1.31822 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m1.31545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 060 | loss: 1.31545 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m1.31260\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 061 | loss: 1.31260 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m1.30966\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 062 | loss: 1.30966 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m1.30664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 063 | loss: 1.30664 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m1.30352\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 064 | loss: 1.30352 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m1.30032\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 065 | loss: 1.30032 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m1.29701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 066 | loss: 1.29701 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m1.29361\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 067 | loss: 1.29361 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m1.29634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 068 | loss: 1.29634 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m1.29205\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 069 | loss: 1.29205 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m1.28777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 070 | loss: 1.28777 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m1.28350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 071 | loss: 1.28350 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m1.27921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 072 | loss: 1.27921 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m1.27488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 073 | loss: 1.27488 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m1.27052\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 074 | loss: 1.27052 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m1.26609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 075 | loss: 1.26609 - acc: 0.5136 -- iter: 8/8\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m1.26160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 076 | loss: 1.26160 - acc: 0.5255 -- iter: 8/8\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m1.25704\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 077 | loss: 1.25704 - acc: 0.5360 -- iter: 8/8\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m1.25241\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 078 | loss: 1.25241 - acc: 0.5453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m1.24769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 079 | loss: 1.24769 - acc: 0.5536 -- iter: 8/8\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m1.24288\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 080 | loss: 1.24288 - acc: 0.5609 -- iter: 8/8\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m1.23799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 081 | loss: 1.23799 - acc: 0.5674 -- iter: 8/8\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m1.23301\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 082 | loss: 1.23301 - acc: 0.5731 -- iter: 8/8\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m1.22788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 083 | loss: 1.22788 - acc: 0.5783 -- iter: 8/8\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m1.22260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 084 | loss: 1.22260 - acc: 0.5830 -- iter: 8/8\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m1.21718\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 085 | loss: 1.21718 - acc: 0.5872 -- iter: 8/8\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m1.21162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 086 | loss: 1.21162 - acc: 0.5910 -- iter: 8/8\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m1.20593\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 087 | loss: 1.20593 - acc: 0.5944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m1.20010\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 088 | loss: 1.20010 - acc: 0.5974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m1.19414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 089 | loss: 1.19414 - acc: 0.6002 -- iter: 8/8\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m1.18806\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 090 | loss: 1.18806 - acc: 0.6027 -- iter: 8/8\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m1.18186\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 091 | loss: 1.18186 - acc: 0.6049 -- iter: 8/8\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m1.17554\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 092 | loss: 1.17554 - acc: 0.6069 -- iter: 8/8\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m1.16910\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 093 | loss: 1.16910 - acc: 0.6087 -- iter: 8/8\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m1.16257\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 094 | loss: 1.16257 - acc: 0.6104 -- iter: 8/8\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m1.15593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 095 | loss: 1.15593 - acc: 0.6118 -- iter: 8/8\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m1.14919\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 096 | loss: 1.14919 - acc: 0.6131 -- iter: 8/8\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m1.14236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 097 | loss: 1.14236 - acc: 0.6143 -- iter: 8/8\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m1.13545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 098 | loss: 1.13545 - acc: 0.6154 -- iter: 8/8\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m1.12847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 099 | loss: 1.12847 - acc: 0.6163 -- iter: 8/8\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m1.12141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 100 | loss: 1.12141 - acc: 0.6172 -- iter: 8/8\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m1.11428\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 101 | loss: 1.11428 - acc: 0.6180 -- iter: 8/8\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m1.10710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 102 | loss: 1.10710 - acc: 0.6187 -- iter: 8/8\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m1.09987\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 103 | loss: 1.09987 - acc: 0.6193 -- iter: 8/8\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m1.09259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 104 | loss: 1.09259 - acc: 0.6199 -- iter: 8/8\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m1.08528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 105 | loss: 1.08528 - acc: 0.6204 -- iter: 8/8\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m1.07793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 106 | loss: 1.07793 - acc: 0.6209 -- iter: 8/8\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m1.07057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 107 | loss: 1.07057 - acc: 0.6213 -- iter: 8/8\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m1.06318\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 108 | loss: 1.06318 - acc: 0.6216 -- iter: 8/8\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m1.05579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 109 | loss: 1.05579 - acc: 0.6220 -- iter: 8/8\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m1.04840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 110 | loss: 1.04840 - acc: 0.6223 -- iter: 8/8\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m1.04102\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 111 | loss: 1.04102 - acc: 0.6226 -- iter: 8/8\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m1.03364\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 112 | loss: 1.03364 - acc: 0.6228 -- iter: 8/8\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m1.02629\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 113 | loss: 1.02629 - acc: 0.6230 -- iter: 8/8\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m1.01895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 114 | loss: 1.01895 - acc: 0.6232 -- iter: 8/8\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m1.01165\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 115 | loss: 1.01165 - acc: 0.6234 -- iter: 8/8\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m1.00439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 116 | loss: 1.00439 - acc: 0.6236 -- iter: 8/8\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.99717\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 117 | loss: 0.99717 - acc: 0.6237 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.98999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 118 | loss: 0.98999 - acc: 0.6238 -- iter: 8/8\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.98287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 119 | loss: 0.98287 - acc: 0.6239 -- iter: 8/8\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.97580\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 120 | loss: 0.97580 - acc: 0.6241 -- iter: 8/8\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.96879\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 121 | loss: 0.96879 - acc: 0.6241 -- iter: 8/8\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.96184\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 122 | loss: 0.96184 - acc: 0.6242 -- iter: 8/8\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.95496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 123 | loss: 0.95496 - acc: 0.6243 -- iter: 8/8\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.94814\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 124 | loss: 0.94814 - acc: 0.6244 -- iter: 8/8\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.94140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 125 | loss: 0.94140 - acc: 0.6244 -- iter: 8/8\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.93472\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 126 | loss: 0.93472 - acc: 0.6245 -- iter: 8/8\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.92812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 127 | loss: 0.92812 - acc: 0.6245 -- iter: 8/8\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.92160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 128 | loss: 0.92160 - acc: 0.6246 -- iter: 8/8\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.91514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 129 | loss: 0.91514 - acc: 0.6246 -- iter: 8/8\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.90876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 130 | loss: 0.90876 - acc: 0.6247 -- iter: 8/8\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.90246\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 131 | loss: 0.90246 - acc: 0.6247 -- iter: 8/8\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.89623\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 132 | loss: 0.89623 - acc: 0.6247 -- iter: 8/8\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.89007\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 133 | loss: 0.89007 - acc: 0.6248 -- iter: 8/8\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.88398\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 134 | loss: 0.88398 - acc: 0.6248 -- iter: 8/8\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.87797\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 135 | loss: 0.87797 - acc: 0.6373 -- iter: 8/8\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.87203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 136 | loss: 0.87203 - acc: 0.6486 -- iter: 8/8\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.86616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 137 | loss: 0.86616 - acc: 0.6587 -- iter: 8/8\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.86035\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 138 | loss: 0.86035 - acc: 0.6678 -- iter: 8/8\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.85461\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 139 | loss: 0.85461 - acc: 0.6761 -- iter: 8/8\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.84894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 140 | loss: 0.84894 - acc: 0.6835 -- iter: 8/8\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.84333\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 141 | loss: 0.84333 - acc: 0.6901 -- iter: 8/8\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.83779\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 142 | loss: 0.83779 - acc: 0.6961 -- iter: 8/8\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.83230\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 143 | loss: 0.83230 - acc: 0.7015 -- iter: 8/8\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.87731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 144 | loss: 0.87731 - acc: 0.6813 -- iter: 8/8\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.86699\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 145 | loss: 0.86699 - acc: 0.6882 -- iter: 8/8\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.85730\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 146 | loss: 0.85730 - acc: 0.6944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.84818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 147 | loss: 0.84818 - acc: 0.6999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.83956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 148 | loss: 0.83956 - acc: 0.7050 -- iter: 8/8\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.83140\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 149 | loss: 0.83140 - acc: 0.7095 -- iter: 8/8\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.82364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 150 | loss: 0.82364 - acc: 0.7135 -- iter: 8/8\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.81624\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 151 | loss: 0.81624 - acc: 0.7172 -- iter: 8/8\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.80917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 152 | loss: 0.80917 - acc: 0.7204 -- iter: 8/8\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.80238\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 153 | loss: 0.80238 - acc: 0.7234 -- iter: 8/8\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.79586\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 154 | loss: 0.79586 - acc: 0.7261 -- iter: 8/8\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.78958\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 155 | loss: 0.78958 - acc: 0.7285 -- iter: 8/8\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.88681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 156 | loss: 0.88681 - acc: 0.6806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.87076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 157 | loss: 0.87076 - acc: 0.6875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.85604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 158 | loss: 0.85604 - acc: 0.6938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.84251\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 159 | loss: 0.84251 - acc: 0.6994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.83005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 160 | loss: 0.83005 - acc: 0.7045 -- iter: 8/8\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.81852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 161 | loss: 0.81852 - acc: 0.7090 -- iter: 8/8\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.80784\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 162 | loss: 0.80784 - acc: 0.7131 -- iter: 8/8\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.79791\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 163 | loss: 0.79791 - acc: 0.7168 -- iter: 8/8\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.78865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 164 | loss: 0.78865 - acc: 0.7201 -- iter: 8/8\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.77998\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 165 | loss: 0.77998 - acc: 0.7231 -- iter: 8/8\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.77185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 166 | loss: 0.77185 - acc: 0.7258 -- iter: 8/8\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.76419\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 167 | loss: 0.76419 - acc: 0.7282 -- iter: 8/8\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.75696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 168 | loss: 0.75696 - acc: 0.7304 -- iter: 8/8\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.75011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 169 | loss: 0.75011 - acc: 0.7324 -- iter: 8/8\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.74359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 170 | loss: 0.74359 - acc: 0.7341 -- iter: 8/8\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.73738\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 171 | loss: 0.73738 - acc: 0.7357 -- iter: 8/8\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.73145\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 172 | loss: 0.73145 - acc: 0.7371 -- iter: 8/8\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.72575\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 173 | loss: 0.72575 - acc: 0.7384 -- iter: 8/8\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.72028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 174 | loss: 0.72028 - acc: 0.7396 -- iter: 8/8\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.71500\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 175 | loss: 0.71500 - acc: 0.7406 -- iter: 8/8\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.70990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 176 | loss: 0.70990 - acc: 0.7416 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.70496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 177 | loss: 0.70496 - acc: 0.7424 -- iter: 8/8\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.70016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 178 | loss: 0.70016 - acc: 0.7432 -- iter: 8/8\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69550\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 179 | loss: 0.69550 - acc: 0.7438 -- iter: 8/8\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69095\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 180 | loss: 0.69095 - acc: 0.7445 -- iter: 8/8\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.68652\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 181 | loss: 0.68652 - acc: 0.7450 -- iter: 8/8\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.68218\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 182 | loss: 0.68218 - acc: 0.7455 -- iter: 8/8\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.67793\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 183 | loss: 0.67793 - acc: 0.7460 -- iter: 8/8\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.67376\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 184 | loss: 0.67376 - acc: 0.7464 -- iter: 8/8\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.66967\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 185 | loss: 0.66967 - acc: 0.7467 -- iter: 8/8\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.66565\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 186 | loss: 0.66565 - acc: 0.7471 -- iter: 8/8\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.66169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 187 | loss: 0.66169 - acc: 0.7474 -- iter: 8/8\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.65780\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 188 | loss: 0.65780 - acc: 0.7476 -- iter: 8/8\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.65396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 189 | loss: 0.65396 - acc: 0.7479 -- iter: 8/8\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.71283\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 190 | loss: 0.71283 - acc: 0.7356 -- iter: 8/8\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.70290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 191 | loss: 0.70290 - acc: 0.7370 -- iter: 8/8\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 192 | loss: 0.69371 - acc: 0.7383 -- iter: 8/8\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.68516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 193 | loss: 0.68516 - acc: 0.7395 -- iter: 8/8\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.67721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 194 | loss: 0.67721 - acc: 0.7405 -- iter: 8/8\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.66978\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 195 | loss: 0.66978 - acc: 0.7415 -- iter: 8/8\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.66282\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 196 | loss: 0.66282 - acc: 0.7423 -- iter: 8/8\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.65628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 197 | loss: 0.65628 - acc: 0.7431 -- iter: 8/8\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.65011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 198 | loss: 0.65011 - acc: 0.7438 -- iter: 8/8\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.64428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 199 | loss: 0.64428 - acc: 0.7444 -- iter: 8/8\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.63876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 200 | loss: 0.63876 - acc: 0.7450 -- iter: 8/8\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.63350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 201 | loss: 0.63350 - acc: 0.7455 -- iter: 8/8\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.62848\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 202 | loss: 0.62848 - acc: 0.7459 -- iter: 8/8\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.62368\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 203 | loss: 0.62368 - acc: 0.7463 -- iter: 8/8\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.61907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 204 | loss: 0.61907 - acc: 0.7467 -- iter: 8/8\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.61464\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 205 | loss: 0.61464 - acc: 0.7470 -- iter: 8/8\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.61037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 206 | loss: 0.61037 - acc: 0.7473 -- iter: 8/8\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.60623\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 207 | loss: 0.60623 - acc: 0.7476 -- iter: 8/8\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.60222\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 208 | loss: 0.60222 - acc: 0.7478 -- iter: 8/8\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 209 | loss: 0.59833 - acc: 0.7482 -- iter: 8/8\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.59454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 210 | loss: 0.59454 - acc: 0.7482 -- iter: 8/8\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.59084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 211 | loss: 0.59084 - acc: 0.7484 -- iter: 8/8\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.58723\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 212 | loss: 0.58723 - acc: 0.7486 -- iter: 8/8\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.58369\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 213 | loss: 0.58369 - acc: 0.7487 -- iter: 8/8\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.58022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 214 | loss: 0.58022 - acc: 0.7488 -- iter: 8/8\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.57682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 215 | loss: 0.57682 - acc: 0.7490 -- iter: 8/8\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.57347\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 216 | loss: 0.57347 - acc: 0.7491 -- iter: 8/8\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.57017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 217 | loss: 0.57017 - acc: 0.7492 -- iter: 8/8\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.56692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 218 | loss: 0.56692 - acc: 0.7492 -- iter: 8/8\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.56371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 219 | loss: 0.56371 - acc: 0.7493 -- iter: 8/8\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.56054\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 220 | loss: 0.56054 - acc: 0.7494 -- iter: 8/8\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.55740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 221 | loss: 0.55740 - acc: 0.7494 -- iter: 8/8\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.55429\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 222 | loss: 0.55429 - acc: 0.7495 -- iter: 8/8\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.55122\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 223 | loss: 0.55122 - acc: 0.7496 -- iter: 8/8\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.54816\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 224 | loss: 0.54816 - acc: 0.7496 -- iter: 8/8\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.54513\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 225 | loss: 0.54513 - acc: 0.7496 -- iter: 8/8\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.66002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 226 | loss: 0.66002 - acc: 0.7247 -- iter: 8/8\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.64534\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 227 | loss: 0.64534 - acc: 0.7272 -- iter: 8/8\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.63193\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 228 | loss: 0.63193 - acc: 0.7295 -- iter: 8/8\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.61966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 229 | loss: 0.61966 - acc: 0.7315 -- iter: 8/8\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.60841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 230 | loss: 0.60841 - acc: 0.7334 -- iter: 8/8\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.59807\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 231 | loss: 0.59807 - acc: 0.7350 -- iter: 8/8\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.58855\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 232 | loss: 0.58855 - acc: 0.7365 -- iter: 8/8\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.57974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 233 | loss: 0.57974 - acc: 0.7379 -- iter: 8/8\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.57158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 234 | loss: 0.57158 - acc: 0.7391 -- iter: 8/8\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.56400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 235 | loss: 0.56400 - acc: 0.7402 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.55693\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 236 | loss: 0.55693 - acc: 0.7412 -- iter: 8/8\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.55032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 237 | loss: 0.55032 - acc: 0.7421 -- iter: 8/8\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.54411\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 238 | loss: 0.54411 - acc: 0.7428 -- iter: 8/8\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.53826\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 239 | loss: 0.53826 - acc: 0.7436 -- iter: 8/8\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.53274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 240 | loss: 0.53274 - acc: 0.7442 -- iter: 8/8\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.52750\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 241 | loss: 0.52750 - acc: 0.7448 -- iter: 8/8\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.52251\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 242 | loss: 0.52251 - acc: 0.7453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.51775\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 243 | loss: 0.51775 - acc: 0.7458 -- iter: 8/8\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.51318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 244 | loss: 0.51318 - acc: 0.7462 -- iter: 8/8\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.50879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 245 | loss: 0.50879 - acc: 0.7466 -- iter: 8/8\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.50456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 246 | loss: 0.50456 - acc: 0.7469 -- iter: 8/8\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.50047\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 247 | loss: 0.50047 - acc: 0.7472 -- iter: 8/8\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.49649\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 248 | loss: 0.49649 - acc: 0.7475 -- iter: 8/8\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.49262\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 249 | loss: 0.49262 - acc: 0.7478 -- iter: 8/8\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.48884\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 250 | loss: 0.48884 - acc: 0.7480 -- iter: 8/8\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.48514\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 251 | loss: 0.48514 - acc: 0.7482 -- iter: 8/8\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.48151\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 252 | loss: 0.48151 - acc: 0.7484 -- iter: 8/8\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.47795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 253 | loss: 0.47795 - acc: 0.7485 -- iter: 8/8\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.47443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 254 | loss: 0.47443 - acc: 0.7487 -- iter: 8/8\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.47095\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 255 | loss: 0.47095 - acc: 0.7488 -- iter: 8/8\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.46751\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 256 | loss: 0.46751 - acc: 0.7489 -- iter: 8/8\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.46410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 257 | loss: 0.46410 - acc: 0.7490 -- iter: 8/8\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.46072\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 258 | loss: 0.46072 - acc: 0.7491 -- iter: 8/8\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.45735\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 259 | loss: 0.45735 - acc: 0.7492 -- iter: 8/8\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.45400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 260 | loss: 0.45400 - acc: 0.7493 -- iter: 8/8\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.45065\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 261 | loss: 0.45065 - acc: 0.7494 -- iter: 8/8\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.65712\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 262 | loss: 0.65712 - acc: 0.6994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.63291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 263 | loss: 0.63291 - acc: 0.7045 -- iter: 8/8\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.61090\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 264 | loss: 0.61090 - acc: 0.7090 -- iter: 8/8\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.59084\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 265 | loss: 0.59084 - acc: 0.7131 -- iter: 8/8\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.57253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 266 | loss: 0.57253 - acc: 0.7168 -- iter: 8/8\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.55580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 267 | loss: 0.55580 - acc: 0.7326 -- iter: 8/8\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.54046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 268 | loss: 0.54046 - acc: 0.7469 -- iter: 8/8\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.52637\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 269 | loss: 0.52637 - acc: 0.7597 -- iter: 8/8\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.51340\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 270 | loss: 0.51340 - acc: 0.7712 -- iter: 8/8\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.50144\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 271 | loss: 0.50144 - acc: 0.7816 -- iter: 8/8\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.49036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 272 | loss: 0.49036 - acc: 0.7909 -- iter: 8/8\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.48008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 273 | loss: 0.48008 - acc: 0.7993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.47050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 274 | loss: 0.47050 - acc: 0.8194 -- iter: 8/8\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.46156\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 275 | loss: 0.46156 - acc: 0.8375 -- iter: 8/8\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.45319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 276 | loss: 0.45319 - acc: 0.8537 -- iter: 8/8\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.44531\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 277 | loss: 0.44531 - acc: 0.8683 -- iter: 8/8\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.43788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 278 | loss: 0.43788 - acc: 0.8815 -- iter: 8/8\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.43085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 279 | loss: 0.43085 - acc: 0.8934 -- iter: 8/8\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.42418\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 280 | loss: 0.42418 - acc: 0.9040 -- iter: 8/8\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.41782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 281 | loss: 0.41782 - acc: 0.9136 -- iter: 8/8\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.41174\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 282 | loss: 0.41174 - acc: 0.9223 -- iter: 8/8\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.40591\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 283 | loss: 0.40591 - acc: 0.9300 -- iter: 8/8\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.40029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 284 | loss: 0.40029 - acc: 0.9370 -- iter: 8/8\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.39488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 285 | loss: 0.39488 - acc: 0.9433 -- iter: 8/8\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.38963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 286 | loss: 0.38963 - acc: 0.9490 -- iter: 8/8\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.38454\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 287 | loss: 0.38454 - acc: 0.9541 -- iter: 8/8\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.37959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 288 | loss: 0.37959 - acc: 0.9587 -- iter: 8/8\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.37476\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 289 | loss: 0.37476 - acc: 0.9628 -- iter: 8/8\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.37003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 290 | loss: 0.37003 - acc: 0.9665 -- iter: 8/8\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.36540\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 291 | loss: 0.36540 - acc: 0.9699 -- iter: 8/8\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.36085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 292 | loss: 0.36085 - acc: 0.9729 -- iter: 8/8\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.35638\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 293 | loss: 0.35638 - acc: 0.9756 -- iter: 8/8\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.35197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 294 | loss: 0.35197 - acc: 0.9780 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.34762\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 295 | loss: 0.34762 - acc: 0.9802 -- iter: 8/8\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.61427\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 296 | loss: 0.61427 - acc: 0.9072 -- iter: 8/8\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.58308\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 297 | loss: 0.58308 - acc: 0.9165 -- iter: 8/8\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.55476\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 298 | loss: 0.55476 - acc: 0.9248 -- iter: 8/8\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.52902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 299 | loss: 0.52902 - acc: 0.9324 -- iter: 8/8\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.50559\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 300 | loss: 0.50559 - acc: 0.9391 -- iter: 8/8\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.48423\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 301 | loss: 0.48423 - acc: 0.9452 -- iter: 8/8\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.46473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 302 | loss: 0.46473 - acc: 0.9507 -- iter: 8/8\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.44688\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 303 | loss: 0.44688 - acc: 0.9556 -- iter: 8/8\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.43052\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 304 | loss: 0.43052 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.41549\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 305 | loss: 0.41549 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.65186\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 306 | loss: 0.65186 - acc: 0.9051 -- iter: 8/8\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.61418\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 307 | loss: 0.61418 - acc: 0.9146 -- iter: 8/8\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.58005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 308 | loss: 0.58005 - acc: 0.9232 -- iter: 8/8\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.54910\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 309 | loss: 0.54910 - acc: 0.9309 -- iter: 8/8\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.52101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 310 | loss: 0.52101 - acc: 0.9378 -- iter: 8/8\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.49547\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 311 | loss: 0.49547 - acc: 0.9440 -- iter: 8/8\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.47222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 312 | loss: 0.47222 - acc: 0.9496 -- iter: 8/8\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.45103\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 313 | loss: 0.45103 - acc: 0.9546 -- iter: 8/8\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.43168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 314 | loss: 0.43168 - acc: 0.9592 -- iter: 8/8\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.41398\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 315 | loss: 0.41398 - acc: 0.9633 -- iter: 8/8\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.39776\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 316 | loss: 0.39776 - acc: 0.9669 -- iter: 8/8\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.38286\u001b[0m\u001b[0m | time: 0.038s\n",
      "| Adam | epoch: 317 | loss: 0.38286 - acc: 0.9702 -- iter: 8/8\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.36915\u001b[0m\u001b[0m | time: 0.072s\n",
      "| Adam | epoch: 318 | loss: 0.36915 - acc: 0.9732 -- iter: 8/8\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.35652\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 319 | loss: 0.35652 - acc: 0.9759 -- iter: 8/8\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.34483\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 320 | loss: 0.34483 - acc: 0.9783 -- iter: 8/8\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.33401\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 321 | loss: 0.33401 - acc: 0.9805 -- iter: 8/8\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.32397\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 322 | loss: 0.32397 - acc: 0.9824 -- iter: 8/8\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.31461\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 323 | loss: 0.31461 - acc: 0.9842 -- iter: 8/8\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.30589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 324 | loss: 0.30589 - acc: 0.9858 -- iter: 8/8\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.29772\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 325 | loss: 0.29772 - acc: 0.9872 -- iter: 8/8\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.29006\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 326 | loss: 0.29006 - acc: 0.9885 -- iter: 8/8\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.28286\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 327 | loss: 0.28286 - acc: 0.9896 -- iter: 8/8\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.27607\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 328 | loss: 0.27607 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.26966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 329 | loss: 0.26966 - acc: 0.9916 -- iter: 8/8\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.26358\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 330 | loss: 0.26358 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.25781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 331 | loss: 0.25781 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.25232\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 332 | loss: 0.25232 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.24708\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 333 | loss: 0.24708 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.24206\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 334 | loss: 0.24206 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.23726\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 335 | loss: 0.23726 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.23265\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 336 | loss: 0.23265 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.22821\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 337 | loss: 0.22821 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.22393\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 338 | loss: 0.22393 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.21980\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 339 | loss: 0.21980 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.21580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 340 | loss: 0.21580 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.21193\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 341 | loss: 0.21193 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.20817\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 342 | loss: 0.20817 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.20452\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 343 | loss: 0.20452 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.20097\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 344 | loss: 0.20097 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.19751\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 345 | loss: 0.19751 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.19414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 346 | loss: 0.19414 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.19086\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 347 | loss: 0.19086 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.18765\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 348 | loss: 0.18765 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.18451\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 349 | loss: 0.18451 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.18144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 350 | loss: 0.18144 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.17843\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 351 | loss: 0.17843 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.17549\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 352 | loss: 0.17549 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.16979\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 353 | loss: 0.16979 - acc: 0.9994 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.16979\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 354 | loss: 0.16979 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.16702\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 355 | loss: 0.16702 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.16431\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 356 | loss: 0.16431 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.16164\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 357 | loss: 0.16164 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.15903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 358 | loss: 0.15903 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.15647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 359 | loss: 0.15647 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.15395\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 360 | loss: 0.15395 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.15148\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 361 | loss: 0.15148 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.14906\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 362 | loss: 0.14906 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.14667\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 363 | loss: 0.14667 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.14434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 364 | loss: 0.14434 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.14204\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 365 | loss: 0.14204 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.13979\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 366 | loss: 0.13979 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.13757\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 367 | loss: 0.13757 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.13540\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 368 | loss: 0.13540 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.13326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 369 | loss: 0.13326 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.13116\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 370 | loss: 0.13116 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.12910\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 371 | loss: 0.12910 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.12708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 372 | loss: 0.12708 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.12510\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 373 | loss: 0.12510 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.12315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 374 | loss: 0.12315 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.12123\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 375 | loss: 0.12123 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.11935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 376 | loss: 0.11935 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.11751\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 377 | loss: 0.11751 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.11569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 378 | loss: 0.11569 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.11392\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 379 | loss: 0.11392 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.11217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 380 | loss: 0.11217 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.11046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 381 | loss: 0.11046 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.10877\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 382 | loss: 0.10877 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.10712\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 383 | loss: 0.10712 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.10550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 384 | loss: 0.10550 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.10391\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 385 | loss: 0.10391 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.10235\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 386 | loss: 0.10235 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.10082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 387 | loss: 0.10082 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.09932\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 388 | loss: 0.09932 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.09784\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 389 | loss: 0.09784 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.09640\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 390 | loss: 0.09640 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.09498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 391 | loss: 0.09498 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.09358\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 392 | loss: 0.09358 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.09222\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 393 | loss: 0.09222 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.09088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 394 | loss: 0.09088 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.08956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 395 | loss: 0.08956 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.08827\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 396 | loss: 0.08827 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.08700\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 397 | loss: 0.08700 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.08576\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 398 | loss: 0.08576 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.08454\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 399 | loss: 0.08454 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.08335\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 400 | loss: 0.08335 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.08218\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 401 | loss: 0.08218 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.08102\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 402 | loss: 0.08102 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.07990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 403 | loss: 0.07990 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.07879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 404 | loss: 0.07879 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.07770\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 405 | loss: 0.07770 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.07664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 406 | loss: 0.07664 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.07559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 407 | loss: 0.07559 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.07456\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 408 | loss: 0.07456 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.07356\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 409 | loss: 0.07356 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.07257\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 410 | loss: 0.07257 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.07160\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 411 | loss: 0.07160 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.07065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 412 | loss: 0.07065 - acc: 1.0000 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.06972\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 413 | loss: 0.06972 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.06880\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 414 | loss: 0.06880 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.06790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 415 | loss: 0.06790 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.06702\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 416 | loss: 0.06702 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.06616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 417 | loss: 0.06616 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.06531\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 418 | loss: 0.06531 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.06447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 419 | loss: 0.06447 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.06366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 420 | loss: 0.06366 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.06285\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 421 | loss: 0.06285 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.06207\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 422 | loss: 0.06207 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.06129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 423 | loss: 0.06129 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.06053\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 424 | loss: 0.06053 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.05979\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 425 | loss: 0.05979 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.05905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 426 | loss: 0.05905 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.05833\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 427 | loss: 0.05833 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.05763\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 428 | loss: 0.05763 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.05693\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 429 | loss: 0.05693 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.05625\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 430 | loss: 0.05625 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.05558\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 431 | loss: 0.05558 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.05493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 432 | loss: 0.05493 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.05428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 433 | loss: 0.05428 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.05365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 434 | loss: 0.05365 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.05303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 435 | loss: 0.05303 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.05241\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 436 | loss: 0.05241 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.05181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 437 | loss: 0.05181 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.05122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 438 | loss: 0.05122 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.05064\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 439 | loss: 0.05064 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.05007\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 440 | loss: 0.05007 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.04951\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 441 | loss: 0.04951 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.04896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 442 | loss: 0.04896 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.04842\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 443 | loss: 0.04842 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.04788\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 444 | loss: 0.04788 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.04736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 445 | loss: 0.04736 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.04684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 446 | loss: 0.04684 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.04634\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 447 | loss: 0.04634 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.04584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 448 | loss: 0.04584 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.04535\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 449 | loss: 0.04535 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.04487\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 450 | loss: 0.04487 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.04439\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 451 | loss: 0.04439 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.04393\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 452 | loss: 0.04393 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.04347\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 453 | loss: 0.04347 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.04302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 454 | loss: 0.04302 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.04258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 455 | loss: 0.04258 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.04214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 456 | loss: 0.04214 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.04171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 457 | loss: 0.04171 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.04129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 458 | loss: 0.04129 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.04087\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 459 | loss: 0.04087 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.21768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 460 | loss: 0.21768 - acc: 0.9500 -- iter: 8/8\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.19959\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 461 | loss: 0.19959 - acc: 0.9550 -- iter: 8/8\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.18331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 462 | loss: 0.18331 - acc: 0.9595 -- iter: 8/8\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.16866\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 463 | loss: 0.16866 - acc: 0.9635 -- iter: 8/8\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.15546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 464 | loss: 0.15546 - acc: 0.9672 -- iter: 8/8\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.14358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 465 | loss: 0.14358 - acc: 0.9705 -- iter: 8/8\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.13287\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 466 | loss: 0.13287 - acc: 0.9734 -- iter: 8/8\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.12322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 467 | loss: 0.12322 - acc: 0.9761 -- iter: 8/8\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.11453\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 468 | loss: 0.11453 - acc: 0.9785 -- iter: 8/8\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.10668\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 469 | loss: 0.10668 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.09961\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 470 | loss: 0.09961 - acc: 0.9826 -- iter: 8/8\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.09322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 471 | loss: 0.09322 - acc: 0.9843 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.08746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 472 | loss: 0.08746 - acc: 0.9859 -- iter: 8/8\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.08225\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 473 | loss: 0.08225 - acc: 0.9873 -- iter: 8/8\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.07754\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 474 | loss: 0.07754 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.07327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 475 | loss: 0.07327 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.06942\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 476 | loss: 0.06942 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.06592\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 477 | loss: 0.06592 - acc: 0.9917 -- iter: 8/8\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.06276\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 478 | loss: 0.06276 - acc: 0.9925 -- iter: 8/8\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.05988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 479 | loss: 0.05988 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.05727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 480 | loss: 0.05727 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.05490\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 481 | loss: 0.05490 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.05274\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 482 | loss: 0.05274 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.05077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 483 | loss: 0.05077 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.04897\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 484 | loss: 0.04897 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.04733\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 485 | loss: 0.04733 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.04583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 486 | loss: 0.04583 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.04445\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 487 | loss: 0.04445 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.04319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 488 | loss: 0.04319 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.04203\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 489 | loss: 0.04203 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.04096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 490 | loss: 0.04096 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.03998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 491 | loss: 0.03998 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.03907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 492 | loss: 0.03907 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.03822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 493 | loss: 0.03822 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.03744\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 494 | loss: 0.03744 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.03671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 495 | loss: 0.03671 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.03603\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 496 | loss: 0.03603 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.03540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 497 | loss: 0.03540 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.03481\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 498 | loss: 0.03481 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.03425\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 499 | loss: 0.03425 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.03373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 500 | loss: 0.03373 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.03323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 501 | loss: 0.03323 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.03277\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 502 | loss: 0.03277 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.03233\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 503 | loss: 0.03233 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.03191\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 504 | loss: 0.03191 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.03151\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 505 | loss: 0.03151 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.03113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 506 | loss: 0.03113 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.03077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 507 | loss: 0.03077 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.03042\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 508 | loss: 0.03042 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.03009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 509 | loss: 0.03009 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.02977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 510 | loss: 0.02977 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.02946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 511 | loss: 0.02946 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.02917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 512 | loss: 0.02917 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.02888\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 513 | loss: 0.02888 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.02860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 514 | loss: 0.02860 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.02833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 515 | loss: 0.02833 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.02807\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 516 | loss: 0.02807 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.02782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 517 | loss: 0.02782 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.02757\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 518 | loss: 0.02757 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.02733\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 519 | loss: 0.02733 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.02710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 520 | loss: 0.02710 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.02687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 521 | loss: 0.02687 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.02664\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 522 | loss: 0.02664 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.02643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 523 | loss: 0.02643 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.02621\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 524 | loss: 0.02621 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.02600\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 525 | loss: 0.02600 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.02579\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 526 | loss: 0.02579 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.02559\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 527 | loss: 0.02559 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.02539\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 528 | loss: 0.02539 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.02520\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 529 | loss: 0.02520 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.02500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 530 | loss: 0.02500 - acc: 1.0000 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.02482\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 531 | loss: 0.02482 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.02463\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 532 | loss: 0.02463 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.02445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 533 | loss: 0.02445 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.02426\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 534 | loss: 0.02426 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.02409\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 535 | loss: 0.02409 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.02391\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 536 | loss: 0.02391 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.02374\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 537 | loss: 0.02374 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.02357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 538 | loss: 0.02357 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.02340\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 539 | loss: 0.02340 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.02323\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 540 | loss: 0.02323 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.02307\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 541 | loss: 0.02307 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.38233\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 542 | loss: 0.38233 - acc: 0.9250 -- iter: 8/8\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.34628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 543 | loss: 0.34628 - acc: 0.9325 -- iter: 8/8\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.31386\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 544 | loss: 0.31386 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.28471\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 545 | loss: 0.28471 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.25850\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 546 | loss: 0.25850 - acc: 0.9508 -- iter: 8/8\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.23492\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 547 | loss: 0.23492 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.21372\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 548 | loss: 0.21372 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.19466\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 549 | loss: 0.19466 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.17751\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 550 | loss: 0.17751 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.16208\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 551 | loss: 0.16208 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.14821\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 552 | loss: 0.14821 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.13572\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 553 | loss: 0.13572 - acc: 0.9765 -- iter: 8/8\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.12449\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 554 | loss: 0.12449 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.11438\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 555 | loss: 0.11438 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.47518\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 556 | loss: 0.47518 - acc: 0.9203 -- iter: 8/8\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.43004\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 557 | loss: 0.43004 - acc: 0.9283 -- iter: 8/8\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.38946\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 558 | loss: 0.38946 - acc: 0.9355 -- iter: 8/8\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.35298\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 559 | loss: 0.35298 - acc: 0.9419 -- iter: 8/8\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.32017\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 560 | loss: 0.32017 - acc: 0.9477 -- iter: 8/8\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.29068\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 561 | loss: 0.29068 - acc: 0.9530 -- iter: 8/8\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.26416\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 562 | loss: 0.26416 - acc: 0.9577 -- iter: 8/8\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.24031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 563 | loss: 0.24031 - acc: 0.9619 -- iter: 8/8\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.21887\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 564 | loss: 0.21887 - acc: 0.9657 -- iter: 8/8\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.19958\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 565 | loss: 0.19958 - acc: 0.9691 -- iter: 8/8\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.18224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 566 | loss: 0.18224 - acc: 0.9722 -- iter: 8/8\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.16664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 567 | loss: 0.16664 - acc: 0.9750 -- iter: 8/8\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.15261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 568 | loss: 0.15261 - acc: 0.9775 -- iter: 8/8\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.13998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 569 | loss: 0.13998 - acc: 0.9798 -- iter: 8/8\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.12862\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 570 | loss: 0.12862 - acc: 0.9818 -- iter: 8/8\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.11839\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 571 | loss: 0.11839 - acc: 0.9836 -- iter: 8/8\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.10919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 572 | loss: 0.10919 - acc: 0.9852 -- iter: 8/8\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.10090\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 573 | loss: 0.10090 - acc: 0.9867 -- iter: 8/8\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.09344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 574 | loss: 0.09344 - acc: 0.9880 -- iter: 8/8\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.08671\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 575 | loss: 0.08671 - acc: 0.9903 -- iter: 8/8\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.08065\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 576 | loss: 0.08065 - acc: 0.9903 -- iter: 8/8\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.07519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 577 | loss: 0.07519 - acc: 0.9913 -- iter: 8/8\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.07026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 578 | loss: 0.07026 - acc: 0.9922 -- iter: 8/8\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.06582\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 579 | loss: 0.06582 - acc: 0.9929 -- iter: 8/8\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.06181\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 580 | loss: 0.06181 - acc: 0.9936 -- iter: 8/8\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.05819\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 581 | loss: 0.05819 - acc: 0.9943 -- iter: 8/8\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.05492\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 582 | loss: 0.05492 - acc: 0.9949 -- iter: 8/8\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.05196\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 583 | loss: 0.05196 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.04929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 584 | loss: 0.04929 - acc: 0.9958 -- iter: 8/8\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.04687\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 585 | loss: 0.04687 - acc: 0.9962 -- iter: 8/8\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.04468\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 586 | loss: 0.04468 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.04269\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 587 | loss: 0.04269 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.04089\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 588 | loss: 0.04089 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.03925\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 589 | loss: 0.03925 - acc: 0.9975 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.03776\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 590 | loss: 0.03776 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.03641\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 591 | loss: 0.03641 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.03518\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 592 | loss: 0.03518 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.03406\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 593 | loss: 0.03406 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.03303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 594 | loss: 0.03303 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.03210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 595 | loss: 0.03210 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.03124\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 596 | loss: 0.03124 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.03046\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 597 | loss: 0.03046 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.02974\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 598 | loss: 0.02974 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.02907\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 599 | loss: 0.02907 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.02846\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 600 | loss: 0.02846 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.02790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 601 | loss: 0.02790 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.02738\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 602 | loss: 0.02738 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.02690\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 603 | loss: 0.02690 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.02645\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 604 | loss: 0.02645 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.02603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 605 | loss: 0.02603 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.02564\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 606 | loss: 0.02564 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.02528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 607 | loss: 0.02528 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.02494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 608 | loss: 0.02494 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.02463\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 609 | loss: 0.02463 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.02433\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 610 | loss: 0.02433 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.02404\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 611 | loss: 0.02404 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.02378\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 612 | loss: 0.02378 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.02353\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 613 | loss: 0.02353 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.02329\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 614 | loss: 0.02329 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.02306\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 615 | loss: 0.02306 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.02284\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 616 | loss: 0.02284 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.02263\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 617 | loss: 0.02263 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.02244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 618 | loss: 0.02244 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.02224\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 619 | loss: 0.02224 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.02206\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 620 | loss: 0.02206 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.02188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 621 | loss: 0.02188 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.02171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 622 | loss: 0.02171 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.02155\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 623 | loss: 0.02155 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.02139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 624 | loss: 0.02139 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.02123\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 625 | loss: 0.02123 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.02108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 626 | loss: 0.02108 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.02094\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 627 | loss: 0.02094 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.02079\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 628 | loss: 0.02079 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.02066\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 629 | loss: 0.02066 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.27258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 630 | loss: 0.27258 - acc: 0.9500 -- iter: 8/8\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.24727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 631 | loss: 0.24727 - acc: 0.9550 -- iter: 8/8\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.22450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 632 | loss: 0.22450 - acc: 0.9635 -- iter: 8/8\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.20403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 633 | loss: 0.20403 - acc: 0.9635 -- iter: 8/8\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.18561\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 634 | loss: 0.18561 - acc: 0.9672 -- iter: 8/8\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.16904\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 635 | loss: 0.16904 - acc: 0.9705 -- iter: 8/8\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.15413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 636 | loss: 0.15413 - acc: 0.9734 -- iter: 8/8\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.14072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 637 | loss: 0.14072 - acc: 0.9761 -- iter: 8/8\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.12866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 638 | loss: 0.12866 - acc: 0.9785 -- iter: 8/8\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.11780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 639 | loss: 0.11780 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.10803\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 640 | loss: 0.10803 - acc: 0.9826 -- iter: 8/8\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.09924\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 641 | loss: 0.09924 - acc: 0.9843 -- iter: 8/8\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.09132\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 642 | loss: 0.09132 - acc: 0.9859 -- iter: 8/8\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.08420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 643 | loss: 0.08420 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.07778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 644 | loss: 0.07778 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.07200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 645 | loss: 0.07200 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.06679\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 646 | loss: 0.06679 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.06210\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 647 | loss: 0.06210 - acc: 0.9917 -- iter: 8/8\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.05788\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 648 | loss: 0.05788 - acc: 0.9925 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.05407\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 649 | loss: 0.05407 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.05063\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 650 | loss: 0.05063 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.04753\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 651 | loss: 0.04753 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.04474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 652 | loss: 0.04474 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.04221\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 653 | loss: 0.04221 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.03993\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 654 | loss: 0.03993 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.03787\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 655 | loss: 0.03787 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.03601\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 656 | loss: 0.03601 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.03433\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 657 | loss: 0.03433 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.03281\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 658 | loss: 0.03281 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.03143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 659 | loss: 0.03143 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.03018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 660 | loss: 0.03018 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.02904\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 661 | loss: 0.02904 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.02801\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 662 | loss: 0.02801 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.02708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 663 | loss: 0.02708 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.02623\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 664 | loss: 0.02623 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.02545\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 665 | loss: 0.02545 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.02474\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 666 | loss: 0.02474 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.02410\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 667 | loss: 0.02410 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.02351\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 668 | loss: 0.02351 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.02297\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 669 | loss: 0.02297 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.02248\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 670 | loss: 0.02248 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.02202\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 671 | loss: 0.02202 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.02161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 672 | loss: 0.02161 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.02122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 673 | loss: 0.02122 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.02087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 674 | loss: 0.02087 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.02054\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 675 | loss: 0.02054 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.27640\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 676 | loss: 0.27640 - acc: 0.9496 -- iter: 8/8\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.25053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 677 | loss: 0.25053 - acc: 0.9546 -- iter: 8/8\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.22726\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 678 | loss: 0.22726 - acc: 0.9592 -- iter: 8/8\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.20633\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 679 | loss: 0.20633 - acc: 0.9633 -- iter: 8/8\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.18750\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 680 | loss: 0.18750 - acc: 0.9669 -- iter: 8/8\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.17057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 681 | loss: 0.17057 - acc: 0.9702 -- iter: 8/8\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.15533\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 682 | loss: 0.15533 - acc: 0.9732 -- iter: 8/8\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.14163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 683 | loss: 0.14163 - acc: 0.9759 -- iter: 8/8\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.12930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 684 | loss: 0.12930 - acc: 0.9783 -- iter: 8/8\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.11820\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 685 | loss: 0.11820 - acc: 0.9805 -- iter: 8/8\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.10822\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 686 | loss: 0.10822 - acc: 0.9824 -- iter: 8/8\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.09924\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 687 | loss: 0.09924 - acc: 0.9842 -- iter: 8/8\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.09115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 688 | loss: 0.09115 - acc: 0.9858 -- iter: 8/8\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.08388\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 689 | loss: 0.08388 - acc: 0.9872 -- iter: 8/8\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.07732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 690 | loss: 0.07732 - acc: 0.9885 -- iter: 8/8\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.07142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 691 | loss: 0.07142 - acc: 0.9896 -- iter: 8/8\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.06611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 692 | loss: 0.06611 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.06133\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 693 | loss: 0.06133 - acc: 0.9916 -- iter: 8/8\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.05702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 694 | loss: 0.05702 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.05313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 695 | loss: 0.05313 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.04963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 696 | loss: 0.04963 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.04647\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 697 | loss: 0.04647 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.04363\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 698 | loss: 0.04363 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.04106\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 699 | loss: 0.04106 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.03874\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 700 | loss: 0.03874 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.03665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 701 | loss: 0.03665 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.03476\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 702 | loss: 0.03476 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.03305\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 703 | loss: 0.03305 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.03150\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 704 | loss: 0.03150 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.03010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 705 | loss: 0.03010 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.02884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 706 | loss: 0.02884 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.02769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 707 | loss: 0.02769 - acc: 0.9981 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.02665\u001b[0m\u001b[0m | time: 0.018s\n",
      "| Adam | epoch: 708 | loss: 0.02665 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.02571\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 709 | loss: 0.02571 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.55001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 710 | loss: 0.55001 - acc: 0.9236 -- iter: 8/8\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.49676\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 711 | loss: 0.49676 - acc: 0.9312 -- iter: 8/8\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.44888\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 712 | loss: 0.44888 - acc: 0.9381 -- iter: 8/8\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.40581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 713 | loss: 0.40581 - acc: 0.9443 -- iter: 8/8\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.36708\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 714 | loss: 0.36708 - acc: 0.9499 -- iter: 8/8\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.33225\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 715 | loss: 0.33225 - acc: 0.9549 -- iter: 8/8\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.30092\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 716 | loss: 0.30092 - acc: 0.9594 -- iter: 8/8\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.27275\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 717 | loss: 0.27275 - acc: 0.9635 -- iter: 8/8\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.24741\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 718 | loss: 0.24741 - acc: 0.9671 -- iter: 8/8\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.22461\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 719 | loss: 0.22461 - acc: 0.9704 -- iter: 8/8\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.20412\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 720 | loss: 0.20412 - acc: 0.9734 -- iter: 8/8\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.18568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 721 | loss: 0.18568 - acc: 0.9760 -- iter: 8/8\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.16909\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 722 | loss: 0.16909 - acc: 0.9784 -- iter: 8/8\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.15417\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 723 | loss: 0.15417 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.14074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 724 | loss: 0.14074 - acc: 0.9825 -- iter: 8/8\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.12867\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 725 | loss: 0.12867 - acc: 0.9843 -- iter: 8/8\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.11780\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 726 | loss: 0.11780 - acc: 0.9858 -- iter: 8/8\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.10802\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 727 | loss: 0.10802 - acc: 0.9873 -- iter: 8/8\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.58804\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 728 | loss: 0.58804 - acc: 0.9135 -- iter: 8/8\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.53128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 729 | loss: 0.53128 - acc: 0.9222 -- iter: 8/8\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.48024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 730 | loss: 0.48024 - acc: 0.9300 -- iter: 8/8\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.43433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 731 | loss: 0.43433 - acc: 0.9370 -- iter: 8/8\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.39305\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 732 | loss: 0.39305 - acc: 0.9433 -- iter: 8/8\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.35593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 733 | loss: 0.35593 - acc: 0.9489 -- iter: 8/8\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.32255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 734 | loss: 0.32255 - acc: 0.9540 -- iter: 8/8\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.29252\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 735 | loss: 0.29252 - acc: 0.9586 -- iter: 8/8\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.26552\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 736 | loss: 0.26552 - acc: 0.9628 -- iter: 8/8\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.24123\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 737 | loss: 0.24123 - acc: 0.9665 -- iter: 8/8\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.21939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 738 | loss: 0.21939 - acc: 0.9699 -- iter: 8/8\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.19974\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 739 | loss: 0.19974 - acc: 0.9729 -- iter: 8/8\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.18207\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 740 | loss: 0.18207 - acc: 0.9756 -- iter: 8/8\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.16617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 741 | loss: 0.16617 - acc: 0.9780 -- iter: 8/8\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.15186\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 742 | loss: 0.15186 - acc: 0.9802 -- iter: 8/8\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.13899\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 743 | loss: 0.13899 - acc: 0.9822 -- iter: 8/8\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.12741\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 744 | loss: 0.12741 - acc: 0.9840 -- iter: 8/8\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.11699\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 745 | loss: 0.11699 - acc: 0.9856 -- iter: 8/8\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.10761\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 746 | loss: 0.10761 - acc: 0.9870 -- iter: 8/8\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.09916\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 747 | loss: 0.09916 - acc: 0.9883 -- iter: 8/8\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.09156\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 748 | loss: 0.09156 - acc: 0.9895 -- iter: 8/8\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.08471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 749 | loss: 0.08471 - acc: 0.9905 -- iter: 8/8\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.07855\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 750 | loss: 0.07855 - acc: 0.9915 -- iter: 8/8\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.07299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 751 | loss: 0.07299 - acc: 0.9923 -- iter: 8/8\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.06798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 752 | loss: 0.06798 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.06347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 753 | loss: 0.06347 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.05940\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 754 | loss: 0.05940 - acc: 0.9944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.05573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 755 | loss: 0.05573 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.05242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 756 | loss: 0.05242 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.04944\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 757 | loss: 0.04944 - acc: 0.9959 -- iter: 8/8\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.04674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 758 | loss: 0.04674 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.04430\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 759 | loss: 0.04430 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.04210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 760 | loss: 0.04210 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.04011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 761 | loss: 0.04011 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.03831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 762 | loss: 0.03831 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.03520\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 763 | loss: 0.03520 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.03520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 764 | loss: 0.03520 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.03386\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 765 | loss: 0.03386 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.03264\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 766 | loss: 0.03264 - acc: 0.9984 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.03154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 767 | loss: 0.03154 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.03053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 768 | loss: 0.03053 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.02962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 769 | loss: 0.02962 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.02879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 770 | loss: 0.02879 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.02803\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 771 | loss: 0.02803 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.36848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 772 | loss: 0.36848 - acc: 0.9242 -- iter: 8/8\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.33376\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 773 | loss: 0.33376 - acc: 0.9317 -- iter: 8/8\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.30255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 774 | loss: 0.30255 - acc: 0.9386 -- iter: 8/8\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.27447\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 775 | loss: 0.27447 - acc: 0.9447 -- iter: 8/8\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.24922\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 776 | loss: 0.24922 - acc: 0.9502 -- iter: 8/8\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.22651\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 777 | loss: 0.22651 - acc: 0.9552 -- iter: 8/8\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.20609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 778 | loss: 0.20609 - acc: 0.9597 -- iter: 8/8\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.18771\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 779 | loss: 0.18771 - acc: 0.9637 -- iter: 8/8\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.62497\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 780 | loss: 0.62497 - acc: 0.8674 -- iter: 8/8\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.56477\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 781 | loss: 0.56477 - acc: 0.8806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.51064\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 782 | loss: 0.51064 - acc: 0.8926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.46197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 783 | loss: 0.46197 - acc: 0.9033 -- iter: 8/8\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.41820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 784 | loss: 0.41820 - acc: 0.9130 -- iter: 8/8\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.37885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 785 | loss: 0.37885 - acc: 0.9217 -- iter: 8/8\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.34346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 786 | loss: 0.34346 - acc: 0.9295 -- iter: 8/8\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.31163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 787 | loss: 0.31163 - acc: 0.9366 -- iter: 8/8\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.28301\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 788 | loss: 0.28301 - acc: 0.9429 -- iter: 8/8\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.25727\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 789 | loss: 0.25727 - acc: 0.9486 -- iter: 8/8\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.23412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 790 | loss: 0.23412 - acc: 0.9537 -- iter: 8/8\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.21330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 791 | loss: 0.21330 - acc: 0.9584 -- iter: 8/8\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.19458\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 792 | loss: 0.19458 - acc: 0.9625 -- iter: 8/8\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.17773\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 793 | loss: 0.17773 - acc: 0.9663 -- iter: 8/8\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.16258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 794 | loss: 0.16258 - acc: 0.9697 -- iter: 8/8\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.14894\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 795 | loss: 0.14894 - acc: 0.9727 -- iter: 8/8\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.13667\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 796 | loss: 0.13667 - acc: 0.9754 -- iter: 8/8\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.12563\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 797 | loss: 0.12563 - acc: 0.9779 -- iter: 8/8\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.11569\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 798 | loss: 0.11569 - acc: 0.9801 -- iter: 8/8\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.10675\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 799 | loss: 0.10675 - acc: 0.9821 -- iter: 8/8\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.44779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 800 | loss: 0.44779 - acc: 0.9214 -- iter: 8/8\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.40567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 801 | loss: 0.40567 - acc: 0.9292 -- iter: 8/8\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.36779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 802 | loss: 0.36779 - acc: 0.9363 -- iter: 8/8\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.33373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 803 | loss: 0.33373 - acc: 0.9427 -- iter: 8/8\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.30310\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 804 | loss: 0.30310 - acc: 0.9484 -- iter: 8/8\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.27555\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 805 | loss: 0.27555 - acc: 0.9536 -- iter: 8/8\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.25078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 806 | loss: 0.25078 - acc: 0.9582 -- iter: 8/8\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.22850\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 807 | loss: 0.22850 - acc: 0.9624 -- iter: 8/8\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.20847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 808 | loss: 0.20847 - acc: 0.9662 -- iter: 8/8\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.19044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 809 | loss: 0.19044 - acc: 0.9695 -- iter: 8/8\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.17423\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 810 | loss: 0.17423 - acc: 0.9726 -- iter: 8/8\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.15964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 811 | loss: 0.15964 - acc: 0.9753 -- iter: 8/8\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.14652\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 812 | loss: 0.14652 - acc: 0.9778 -- iter: 8/8\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.13471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 813 | loss: 0.13471 - acc: 0.9800 -- iter: 8/8\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.44190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 814 | loss: 0.44190 - acc: 0.9070 -- iter: 8/8\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.40060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 815 | loss: 0.40060 - acc: 0.9163 -- iter: 8/8\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.36346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 816 | loss: 0.36346 - acc: 0.9247 -- iter: 8/8\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.33007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 817 | loss: 0.33007 - acc: 0.9322 -- iter: 8/8\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.30005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 818 | loss: 0.30005 - acc: 0.9390 -- iter: 8/8\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.27306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 819 | loss: 0.27306 - acc: 0.9451 -- iter: 8/8\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.24878\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 820 | loss: 0.24878 - acc: 0.9506 -- iter: 8/8\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.22695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 821 | loss: 0.22695 - acc: 0.9555 -- iter: 8/8\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.20731\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 822 | loss: 0.20731 - acc: 0.9600 -- iter: 8/8\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.18965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 823 | loss: 0.18965 - acc: 0.9640 -- iter: 8/8\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.59194\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 824 | loss: 0.59194 - acc: 0.8926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.53588\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 825 | loss: 0.53588 - acc: 0.9033 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.48548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 826 | loss: 0.48548 - acc: 0.9130 -- iter: 8/8\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.44016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 827 | loss: 0.44016 - acc: 0.9217 -- iter: 8/8\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.39942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 828 | loss: 0.39942 - acc: 0.9295 -- iter: 8/8\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.36278\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 829 | loss: 0.36278 - acc: 0.9366 -- iter: 8/8\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.32984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 830 | loss: 0.32984 - acc: 0.9429 -- iter: 8/8\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.30021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 831 | loss: 0.30021 - acc: 0.9486 -- iter: 8/8\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.27357\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 832 | loss: 0.27357 - acc: 0.9538 -- iter: 8/8\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.24961\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 833 | loss: 0.24961 - acc: 0.9584 -- iter: 8/8\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.22806\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 834 | loss: 0.22806 - acc: 0.9625 -- iter: 8/8\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.20868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 835 | loss: 0.20868 - acc: 0.9663 -- iter: 8/8\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.19124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 836 | loss: 0.19124 - acc: 0.9697 -- iter: 8/8\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.17555\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 837 | loss: 0.17555 - acc: 0.9727 -- iter: 8/8\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.16143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 838 | loss: 0.16143 - acc: 0.9754 -- iter: 8/8\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.14872\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 839 | loss: 0.14872 - acc: 0.9779 -- iter: 8/8\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.13728\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 840 | loss: 0.13728 - acc: 0.9801 -- iter: 8/8\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.12698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 841 | loss: 0.12698 - acc: 0.9821 -- iter: 8/8\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.11770\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 842 | loss: 0.11770 - acc: 0.9839 -- iter: 8/8\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.10935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 843 | loss: 0.10935 - acc: 0.9855 -- iter: 8/8\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.10182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 844 | loss: 0.10182 - acc: 0.9869 -- iter: 8/8\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.09504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 845 | loss: 0.09504 - acc: 0.9882 -- iter: 8/8\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.08892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 846 | loss: 0.08892 - acc: 0.9894 -- iter: 8/8\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.08340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 847 | loss: 0.08340 - acc: 0.9905 -- iter: 8/8\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.07843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 848 | loss: 0.07843 - acc: 0.9914 -- iter: 8/8\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.07393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 849 | loss: 0.07393 - acc: 0.9923 -- iter: 8/8\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.06988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 850 | loss: 0.06988 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.06621\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 851 | loss: 0.06621 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.06290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 852 | loss: 0.06290 - acc: 0.9944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.05990\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 853 | loss: 0.05990 - acc: 0.9949 -- iter: 8/8\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.05719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 854 | loss: 0.05719 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.05473\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 855 | loss: 0.05473 - acc: 0.9959 -- iter: 8/8\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.05251\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 856 | loss: 0.05251 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.05049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 857 | loss: 0.05049 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.04865\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 858 | loss: 0.04865 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.04698\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 859 | loss: 0.04698 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.04547\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 860 | loss: 0.04547 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.04409\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 861 | loss: 0.04409 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.04282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 862 | loss: 0.04282 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.04167\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 863 | loss: 0.04167 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.04062\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 864 | loss: 0.04062 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.03966\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 865 | loss: 0.03966 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.03877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 866 | loss: 0.03877 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.03796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 867 | loss: 0.03796 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.03721\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 868 | loss: 0.03721 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.03652\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 869 | loss: 0.03652 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.03589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 870 | loss: 0.03589 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.03530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 871 | loss: 0.03530 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.03475\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 872 | loss: 0.03475 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.03424\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 873 | loss: 0.03424 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.03377\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 874 | loss: 0.03377 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.03332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 875 | loss: 0.03332 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.03291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 876 | loss: 0.03291 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.03252\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 877 | loss: 0.03252 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.03216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 878 | loss: 0.03216 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.03181\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 879 | loss: 0.03181 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.03149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 880 | loss: 0.03149 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.03118\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 881 | loss: 0.03118 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.03088\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 882 | loss: 0.03088 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.03061\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 883 | loss: 0.03061 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.03034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 884 | loss: 0.03034 - acc: 0.9998 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.03008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 885 | loss: 0.03008 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.02984\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 886 | loss: 0.02984 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.02961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 887 | loss: 0.02961 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.02938\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 888 | loss: 0.02938 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.02916\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 889 | loss: 0.02916 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.02895\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 890 | loss: 0.02895 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.02875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 891 | loss: 0.02875 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.44797\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 892 | loss: 0.44797 - acc: 0.9249 -- iter: 8/8\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.40589\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 893 | loss: 0.40589 - acc: 0.9324 -- iter: 8/8\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.36805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 894 | loss: 0.36805 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.33402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 895 | loss: 0.33402 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.30341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 896 | loss: 0.30341 - acc: 0.9507 -- iter: 8/8\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.27589\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 897 | loss: 0.27589 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.25114\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 898 | loss: 0.25114 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.22887\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 899 | loss: 0.22887 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.20885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 900 | loss: 0.20885 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.19083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 901 | loss: 0.19083 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.17463\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 902 | loss: 0.17463 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.16005\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 903 | loss: 0.16005 - acc: 0.9764 -- iter: 8/8\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.14693\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 904 | loss: 0.14693 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.13512\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 905 | loss: 0.13512 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.12450\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 906 | loss: 0.12450 - acc: 0.9828 -- iter: 8/8\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.11493\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 907 | loss: 0.11493 - acc: 0.9845 -- iter: 8/8\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.10632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 908 | loss: 0.10632 - acc: 0.9861 -- iter: 8/8\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.09856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 909 | loss: 0.09856 - acc: 0.9875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.09158\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 910 | loss: 0.09158 - acc: 0.9887 -- iter: 8/8\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.08528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 911 | loss: 0.08528 - acc: 0.9899 -- iter: 8/8\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.07961\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 912 | loss: 0.07961 - acc: 0.9909 -- iter: 8/8\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.07450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 913 | loss: 0.07450 - acc: 0.9918 -- iter: 8/8\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.06989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 914 | loss: 0.06989 - acc: 0.9926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.06573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 915 | loss: 0.06573 - acc: 0.9933 -- iter: 8/8\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.06198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 916 | loss: 0.06198 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.05859\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 917 | loss: 0.05859 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.47734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 918 | loss: 0.47734 - acc: 0.9076 -- iter: 8/8\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.43245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 919 | loss: 0.43245 - acc: 0.9169 -- iter: 8/8\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.39208\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 920 | loss: 0.39208 - acc: 0.9252 -- iter: 8/8\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.35578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 921 | loss: 0.35578 - acc: 0.9327 -- iter: 8/8\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.32314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 922 | loss: 0.32314 - acc: 0.9394 -- iter: 8/8\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.29379\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 923 | loss: 0.29379 - acc: 0.9455 -- iter: 8/8\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.26740\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 924 | loss: 0.26740 - acc: 0.9509 -- iter: 8/8\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.24366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 925 | loss: 0.24366 - acc: 0.9558 -- iter: 8/8\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.63146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 926 | loss: 0.63146 - acc: 0.8727 -- iter: 8/8\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.57139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 927 | loss: 0.57139 - acc: 0.8855 -- iter: 8/8\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.51738\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 928 | loss: 0.51738 - acc: 0.8969 -- iter: 8/8\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.46883\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 929 | loss: 0.46883 - acc: 0.9072 -- iter: 8/8\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.42518\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 930 | loss: 0.42518 - acc: 0.9165 -- iter: 8/8\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.38593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 931 | loss: 0.38593 - acc: 0.9249 -- iter: 8/8\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.35064\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 932 | loss: 0.35064 - acc: 0.9324 -- iter: 8/8\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.31890\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 933 | loss: 0.31890 - acc: 0.9391 -- iter: 8/8\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.29037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 934 | loss: 0.29037 - acc: 0.9452 -- iter: 8/8\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.26471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 935 | loss: 0.26471 - acc: 0.9507 -- iter: 8/8\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.24163\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 936 | loss: 0.24163 - acc: 0.9556 -- iter: 8/8\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.22087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 937 | loss: 0.22087 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.20219\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 938 | loss: 0.20219 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.18539\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 939 | loss: 0.18539 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.35499\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 940 | loss: 0.35499 - acc: 0.9209 -- iter: 8/8\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.32294\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 941 | loss: 0.32294 - acc: 0.9288 -- iter: 8/8\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.29412\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 942 | loss: 0.29412 - acc: 0.9359 -- iter: 8/8\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.26820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 943 | loss: 0.26820 - acc: 0.9423 -- iter: 8/8\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.24489\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 944 | loss: 0.24489 - acc: 0.9481 -- iter: 8/8\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.22392\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 945 | loss: 0.22392 - acc: 0.9533 -- iter: 8/8\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.20505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 946 | loss: 0.20505 - acc: 0.9580 -- iter: 8/8\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.18808\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 947 | loss: 0.18808 - acc: 0.9622 -- iter: 8/8\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.17280\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 948 | loss: 0.17280 - acc: 0.9659 -- iter: 8/8\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.15906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 949 | loss: 0.15906 - acc: 0.9694 -- iter: 8/8\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.14669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 950 | loss: 0.14669 - acc: 0.9724 -- iter: 8/8\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.13555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 951 | loss: 0.13555 - acc: 0.9752 -- iter: 8/8\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.12552\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 952 | loss: 0.12552 - acc: 0.9777 -- iter: 8/8\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.11648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 953 | loss: 0.11648 - acc: 0.9799 -- iter: 8/8\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.10834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 954 | loss: 0.10834 - acc: 0.9819 -- iter: 8/8\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.10101\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 955 | loss: 0.10101 - acc: 0.9837 -- iter: 8/8\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.09440\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 956 | loss: 0.09440 - acc: 0.9853 -- iter: 8/8\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.08844\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 957 | loss: 0.08844 - acc: 0.9868 -- iter: 8/8\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.08306\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 958 | loss: 0.08306 - acc: 0.9881 -- iter: 8/8\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.07821\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 959 | loss: 0.07821 - acc: 0.9893 -- iter: 8/8\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.07383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 960 | loss: 0.07383 - acc: 0.9904 -- iter: 8/8\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.06987\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 961 | loss: 0.06987 - acc: 0.9913 -- iter: 8/8\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.06629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 962 | loss: 0.06629 - acc: 0.9922 -- iter: 8/8\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.06306\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 963 | loss: 0.06306 - acc: 0.9930 -- iter: 8/8\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.06014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 964 | loss: 0.06014 - acc: 0.9937 -- iter: 8/8\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.05749\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 965 | loss: 0.05749 - acc: 0.9943 -- iter: 8/8\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.05509\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 966 | loss: 0.05509 - acc: 0.9949 -- iter: 8/8\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.05291\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 967 | loss: 0.05291 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.05094\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 968 | loss: 0.05094 - acc: 0.9959 -- iter: 8/8\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.04914\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 969 | loss: 0.04914 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.04751\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 970 | loss: 0.04751 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.04603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 971 | loss: 0.04603 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.04467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 972 | loss: 0.04467 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.04344\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 973 | loss: 0.04344 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.04231\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 974 | loss: 0.04231 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.04128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 975 | loss: 0.04128 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.04033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 976 | loss: 0.04033 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.03946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 977 | loss: 0.03946 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.03866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 978 | loss: 0.03866 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.03793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 979 | loss: 0.03793 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.03725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 980 | loss: 0.03725 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.03662\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 981 | loss: 0.03662 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.03604\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 982 | loss: 0.03604 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.03550\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 983 | loss: 0.03550 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.03500\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 984 | loss: 0.03500 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.03453\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 985 | loss: 0.03453 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.03409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 986 | loss: 0.03409 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.03368\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 987 | loss: 0.03368 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.03329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 988 | loss: 0.03329 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.03293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 989 | loss: 0.03293 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.03259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 990 | loss: 0.03259 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.03227\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 991 | loss: 0.03227 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.03196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 992 | loss: 0.03196 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.03167\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 993 | loss: 0.03167 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.46589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 994 | loss: 0.46589 - acc: 0.9122 -- iter: 8/8\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.42223\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 995 | loss: 0.42223 - acc: 0.9210 -- iter: 8/8\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.38296\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 996 | loss: 0.38296 - acc: 0.9289 -- iter: 8/8\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.34765\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 997 | loss: 0.34765 - acc: 0.9360 -- iter: 8/8\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.31589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 998 | loss: 0.31589 - acc: 0.9424 -- iter: 8/8\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.28733\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 999 | loss: 0.28733 - acc: 0.9482 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.26165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1000 | loss: 0.26165 - acc: 0.9534 -- iter: 8/8\n",
      "--\n",
      "INFO:tensorflow:/Volumes/Bi DANG/CFAINSTA/Codespace/TensorFlow/chatbot/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = []\n",
    "words_labels = []\n",
    "docs_x = []\n",
    "docs_y = []\n",
    "\n",
    "\n",
    "def trainingModel(words,words_labels,docs_x,docs_y, epoches=1000):\n",
    "    stemmer = LancasterStemmer()\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    # Récuperee data dans le fichier\n",
    "    with open('messages.json') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # travailler sur des données\n",
    "    for mess in data['messages']:\n",
    "        for pattern in mess['patterns']:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(mess[\"tag\"])\n",
    "\n",
    "        if mess['tag'] not in words_labels:\n",
    "            words_labels.append(mess['tag'])\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    words_labels = sorted(words_labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(words_labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[words_labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "        \n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)\n",
    "    \n",
    "    # Start training model\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "    net = tflearn.fully_connected(net, 8)\n",
    "    net = tflearn.fully_connected(net, 8)\n",
    "    net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "    net = tflearn.regression(net)\n",
    "\n",
    "    model = tflearn.DNN(net)\n",
    "\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(\"model.tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3f3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencer la conversation (exit pour arrêter)!\n",
      "Vous: hey\n",
      "Bonjour\n",
      "Vous: Merci\n",
      "Il n'y a pas de quoi\n",
      "Vous: merci\n",
      "De rien\n",
      "Vous: test\n",
      "Bonjour\n",
      "Vous: bye\n",
      "Bonjour\n",
      "Vous: revoir\n",
      "Au revoir\n",
      "Vous: au revoir\n",
      "A bientôt\n",
      "Vous: hey\n",
      "Bonjour\n",
      "Vous: \n",
      "Bonjour\n",
      "Vous:  \n",
      "Bonjour\n",
      "Vous: exit\n"
     ]
    }
   ],
   "source": [
    "def wordsContainer(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "            \n",
    "    return numpy.array(bag)\n",
    "\n",
    "\n",
    "def lauchConversation():\n",
    "    print(\"Commencer la conversation (exit pour arrêter)!\")\n",
    "    while True:\n",
    "        inp = input(\"Vous: \")\n",
    "        if inp.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        results = model.predict([wordsContainer(inp, words)])\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = words_labels[results_index]\n",
    "\n",
    "        for tg in data[\"messages\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['responses']\n",
    "\n",
    "        print(random.choice(responses))\n",
    "\n",
    "lauchConversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abf850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290e663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
